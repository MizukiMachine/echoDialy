/**
 * Voice Input Module
 * Handles audio recording and speech-to-text conversion
 */

import OpenAI from 'openai';
import { exec } from 'child_process';
import { promisify } from 'util';
import fs from 'fs/promises';
import path from 'path';

const execAsync = promisify(exec);

export interface VoiceInputResult {
  text: string;
  duration: number;
  timestamp: Date;
  audioPath: string;
}

export interface VoiceOptions {
  openaiApiKey: string;
  outputDir?: string;
  duration?: number; // éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
}

/**
 * Record audio using system command (arecord for Linux)
 */
async function recordAudio(
  outputPath: string,
  duration: number = 10
): Promise<void> {
  const command = `arecord -f cd -r 16000 -d ${duration} ${outputPath}`;
  await execAsync(command);
}

/**
 * Transcribe audio to text using Whisper API
 */
async function transcribeWithWhisper(
  audioPath: string,
  openaiApiKey: string
): Promise<string> {
  const openai = new OpenAI({ apiKey: openaiApiKey });

  const transcription = await openai.audio.transcriptions.create({
    file: await fs.readFile(audioPath) as any,
    model: 'whisper-1',
    language: 'ja',
  });

  return transcription.text;
}

/**
 * Record audio and convert to text
 */
export async function recordVoice(
  options: VoiceOptions
): Promise<VoiceInputResult> {
  const {
    openaiApiKey,
    outputDir = './data/audio',
    duration = 10,
  } = options;

  // å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
  await fs.mkdir(outputDir, { recursive: true });

  // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ç”Ÿæˆ
  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
  const audioPath = path.join(outputDir, `recording-${timestamp}.wav`);

  console.log(`ğŸ™ï¸  éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã™ (${duration}ç§’é–“)...`);
  console.log('   è©±ã—ã¦ãã ã•ã„...');

  const startTime = Date.now();

  // éŒ²éŸ³å®Ÿè¡Œ
  await recordAudio(audioPath, duration);

  const endTime = Date.now();
  const actualDuration = (endTime - startTime) / 1000;

  console.log(`âœ“ éŒ²éŸ³å®Œäº† (${actualDuration.toFixed(1)}ç§’)`);

  // Whisper APIã§ãƒ†ã‚­ã‚¹ãƒˆåŒ–
  console.log('ğŸ”„ éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...');
  const text = await transcribeWithWhisper(audioPath, openaiApiKey);

  console.log(`âœ“ å¤‰æ›å®Œäº†:`);
  console.log(`   "${text}"`);

  return {
    text,
    duration: actualDuration,
    timestamp: new Date(),
    audioPath,
  };
}

/**
 * Allow user to edit the transcribed text
 */
export async function editText(originalText: string): Promise<string> {
  console.log('\nğŸ“ ãƒ†ã‚­ã‚¹ãƒˆç·¨é›†:');
  console.log(`ç¾åœ¨: "${originalText}"`);
  console.log('ç·¨é›†ã™ã‚‹å ´åˆã¯æ–°ã—ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ï¼ˆEnterã§ãã®ã¾ã¾ä½¿ç”¨ï¼‰');

  // ç°¡æ˜“å®Ÿè£…ï¼šæ¨™æº–å…¥åŠ›ã‹ã‚‰èª­ã¿å–ã‚Š
  const readline = require('readline');
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });

  return new Promise((resolve) => {
    rl.question('>>> ', (answer: string) => {
      rl.close();
      resolve(answer.trim() || originalText);
    });
  });
}
